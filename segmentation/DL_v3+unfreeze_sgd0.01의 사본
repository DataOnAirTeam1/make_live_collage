{"cells":[{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":472,"status":"ok","timestamp":1660909197029,"user":{"displayName":"이우원","userId":"05495556713808915653"},"user_tz":-540},"id":"r-q6KMwWtQWa","outputId":"008c63bb-c43d-4bcc-ee75-32c33b02c999"},"outputs":[{"name":"stdout","output_type":"stream","text":["2.8.0\n","True\n","True\n","/device:GPU:0\n"]}],"source":["# !pip install tensorflow_addons\n","# !pip install tensorflow==2.8\n","# !apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2\n","\n","import tensorflow as tf\n","print(tf.__version__)\n","print(tf.test.is_built_with_cuda())  # cuda로 빌드되는지 확인\n","print(tf.test.is_built_with_gpu_support())  # cuda와 같은 gpu로 빌드되는지 확인\n","print(tf.test.gpu_device_name())  "]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2260,"status":"ok","timestamp":1660909199936,"user":{"displayName":"이우원","userId":"05495556713808915653"},"user_tz":-540},"id":"KJCN058SLgyp","outputId":"a2300a74-7c71-42c9-9858-e7161e40428f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import tensorflow_addons as tfa\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import numpy as np\n","import cv2\n","import os\n","import random\n","\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras import layers\n","from tensorflow import keras\n","from google.colab import drive\n","from glob import glob\n","\n","from keras import backend as K\n","from keras.utils import io_utils\n","from tensorflow.python.platform import tf_logging as logging\n","\n","drive.mount('/content/drive')\n","os.chdir('/content/drive/MyDrive/Colab Notebooks/collage/segmentation')"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1660909199937,"user":{"displayName":"이우원","userId":"05495556713808915653"},"user_tz":-540},"id":"QzZuAuXtwXbe"},"outputs":[],"source":["rs = 722\n","IMAGE_SIZE = 512\n","BATCH_SIZE = 8\n","NUM_CLASSES = 1\n","\n","def seed_everything(seed):\n","    random.seed(seed)\n","    # os.environ['PYTHONHASHSEED'] = str(seed)\n","    # os.environ['TF_DETERMINISTIC_OPS'] = '1'\n","    np.random.seed(seed)\n","    tf.random.set_seed(seed)\n","seed_everything(rs)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":1708,"status":"ok","timestamp":1660909201639,"user":{"displayName":"이우원","userId":"05495556713808915653"},"user_tz":-540},"id":"ETU20GzMODpD"},"outputs":[],"source":["DATA_DIR = \"/content/drive/MyDrive/Colab Notebooks/collage/segmentation/data/rawdata/\"\n","\n","all_images = sorted(glob(os.path.join(DATA_DIR, \"humanparsing/val/Images/*\"))+glob(os.path.join(DATA_DIR, \"humanparsing/train/Images/*\"))+glob(os.path.join(DATA_DIR, \"fashion/JPEGImages/*\")))\n","all_masks = sorted(glob(os.path.join(DATA_DIR, \"humanparsing/val/Human/*\"))+glob(os.path.join(DATA_DIR, \"humanparsing/train/Human/*\"))+glob(os.path.join(DATA_DIR, \"fashion/SegmentationClassAug/*\")))\n","\n","val_size = 5000\n","train_images, val_images, train_masks, val_masks  = train_test_split(all_images, all_masks, test_size=val_size, random_state=rs)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1511,"status":"ok","timestamp":1660909203147,"user":{"displayName":"이우원","userId":"05495556713808915653"},"user_tz":-540},"id":"5uhIDgL3Lgys","outputId":"f1034fdd-7ded-40fe-bae4-12843ab8d8c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Dataset: \u003cBatchDataset element_spec=(TensorSpec(shape=(8, 512, 512, 3), dtype=tf.float32, name=None), TensorSpec(shape=(8, 512, 512, 1), dtype=tf.float32, name=None))\u003e\n","Validation Dataset: \u003cBatchDataset element_spec=(TensorSpec(shape=(8, 512, 512, 3), dtype=tf.float32, name=None), TensorSpec(shape=(8, 512, 512, 1), dtype=tf.float32, name=None))\u003e\n"]}],"source":["def read_image(image_path, mask=False):\n","  image = tf.io.read_file(image_path)\n","  image = tf.image.decode_png(image, channels=3)\n","  image.set_shape([None, None, 3])\n","  image = tf.image.resize(images=image, size=[IMAGE_SIZE, IMAGE_SIZE])\n","  if not mask:\n","      image = image / 255\n","  return image\n","\n","def load_data(image_list, mask_list):\n","  image = read_image(image_list)\n","  mask = read_image(mask_list, mask=True)\n","  return image, mask\n","\n","def random_crop(input_image, real_image, size):\n","  stacked_image = tf.stack([input_image, real_image], axis=0)\n","  cropped_image = tf.image.random_crop(\n","      stacked_image, size=[2, size, size, 3])\n","  img,msk = cropped_image[0], cropped_image[1]\n","  return img,msk\n","\n","def augment(input_image, input_mask):\n","\n","  if tf.random.uniform(()) \u003e 0.3:\n","      ratio = tf.random.uniform(shape=[],minval=400, maxval=440, dtype=tf.int32)\n","      input_image, input_mask = random_crop(input_image, input_mask, ratio)\n","      input_image = tf.image.resize(input_image, (IMAGE_SIZE, IMAGE_SIZE))\n","      input_mask = tf.image.resize(input_mask, (IMAGE_SIZE, IMAGE_SIZE))\n","\n","  input_image = tf.image.random_brightness(input_image, 0.2)\n","\n","  saturation_factor = tf.random.uniform((),0,2)\n","  input_image = tf.image.adjust_saturation(input_image, saturation_factor)\n","\n","  if tf.random.uniform(()) \u003e 0.5:\n","      input_image = tf.image.flip_left_right(input_image)\n","      input_mask = tf.image.flip_left_right(input_mask)\n","\n","  rot_factor = tf.cast(tf.random.uniform(shape=[],minval=-6, maxval=6, dtype=tf.int32), tf.float32)\n","  angle = np.pi/(12*6) *rot_factor\n","  input_image = tfa.image.rotate(input_image, angle)\n","  input_mask = tfa.image.rotate(input_mask, angle)\n","\n","  return input_image, input_mask\n","\n","def cast_mask(input_image, input_mask):\n","  input_mask = tf.math.reduce_sum(input_mask, axis=2)\n","  input_mask = input_mask[..., tf.newaxis]\n","  input_mask = tf.cast(input_mask\u003e0, dtype=tf.float32)\n","  return input_image,input_mask\n","\n","def data_generator(image_list, mask_list, augument=True):\n","  dataset = tf.data.Dataset.from_tensor_slices((image_list, mask_list))\n","  dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n","  if augument:\n","    dataset = dataset.map(augment)\n","  dataset = dataset.map(cast_mask)\n","  dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n","  return dataset\n","\n","train_dataset = data_generator(train_images, train_masks)\n","print(\"Train Dataset:\", train_dataset)\n","\n","val_dataset = data_generator(val_images, val_masks, augument=False)\n","print(\"Validation Dataset:\", val_dataset)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1660909203148,"user":{"displayName":"이우원","userId":"05495556713808915653"},"user_tz":-540},"id":"mscID--oLgyv"},"outputs":[],"source":["def convolution_block(\n","    block_input,\n","    num_filters=256,\n","    kernel_size=3,\n","    dilation_rate=1,\n","    padding=\"same\",\n","    use_bias=False,\n","):\n","    x = layers.Conv2D(\n","        num_filters,\n","        kernel_size=kernel_size,\n","        dilation_rate=dilation_rate,\n","        padding=\"same\",\n","        use_bias=use_bias,\n","        kernel_initializer=keras.initializers.HeNormal(),\n","    )(block_input)\n","    x = layers.BatchNormalization()(x)\n","    return tf.nn.relu(x)\n","\n","\n","def DilatedSpatialPyramidPooling(dspp_input):\n","    dims = dspp_input.shape\n","    x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n","    x = convolution_block(x, kernel_size=1, use_bias=True)\n","    out_pool = layers.UpSampling2D(\n","        size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"bilinear\",\n","    )(x)\n","\n","    out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n","    out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n","    out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n","    out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n","\n","    x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n","    output = convolution_block(x, kernel_size=1)\n","    return output\n","\n","def SE_block(input_tensor, reduction_ratio=8):\n","    ch_input = K.int_shape(input_tensor)[-1]\n","    ch_reduced = ch_input//reduction_ratio  \n","    # Squeeze\n","    x = layers.GlobalAveragePooling2D()(input_tensor)\n","    # Excitation\n","    x = layers.Dense(ch_reduced, kernel_initializer='he_normal', activation='relu', use_bias=False)(x) \n","    x = layers.Dense(ch_input, kernel_initializer='he_normal', activation='sigmoid', use_bias=False)(x)\n","    x = layers.Reshape((1, 1, ch_input))(x)\n","    x = layers.Multiply()([input_tensor, x])\n","    \n","    return x"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1660909203148,"user":{"displayName":"이우원","userId":"05495556713808915653"},"user_tz":-540},"id":"xLGVfa3bLgyz"},"outputs":[],"source":["def DeeplabV3Plus(image_size, num_classes, find_tunebackbone=False):\n","    model_input = keras.Input(shape=(image_size, image_size, 3))\n","    effiucientnetV2M = keras.applications.EfficientNetV2M(\n","        weights=\"imagenet\", include_top=False, input_tensor=model_input\n","    )\n","    if not find_tunebackbone:\n","      for layer in effiucientnetV2M.layers:\n","        if '_bn' not in layer.name:\n","          layer.trainable = False\n","    x = effiucientnetV2M.get_layer(\"block6a_expand_activation\").output\n","    x = DilatedSpatialPyramidPooling(x)\n","    # x = SE_block(x)\n","    input_a = layers.UpSampling2D(\n","        size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]),\n","        interpolation=\"bilinear\",\n","    )(x)\n","    input_b = effiucientnetV2M.get_layer(\"block2e_add\").output\n","    input_b = convolution_block(input_b, num_filters=48, kernel_size=1)\n","\n","    x = layers.Concatenate(axis=-1)([input_a, input_b])\n","    x = convolution_block(x)\n","    x = convolution_block(x)\n","    x = layers.UpSampling2D(\n","        size=(image_size // x.shape[1], image_size // x.shape[2]),\n","        interpolation=\"bilinear\",\n","    )(x)\n","    model_output = layers.Conv2D(num_classes, kernel_size=(1, 1), padding=\"same\", activation='sigmoid')(x)\n","    return keras.Model(inputs=model_input, outputs=model_output)"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1660909203149,"user":{"displayName":"이우원","userId":"05495556713808915653"},"user_tz":-540},"id":"BCW9gMU7HXjY"},"outputs":[],"source":["class unfreeze_layers_reduce_lr(tf.keras.callbacks.ReduceLROnPlateau):\n","\n","  def __init__(self,\n","               monitor='val_loss',\n","               factor=0.1,\n","               patience=10,\n","               verbose=0,\n","               mode='auto',\n","               min_delta=1e-4,\n","               cooldown=0,\n","               min_lr=0,\n","               freezed=False,\n","               **kwargs):\n","      super().__init__(monitor, factor, patience, verbose, mode, min_delta, cooldown, min_lr)\n","      self.freezed = False\n","\n","\n","  def on_epoch_end(self, epoch, logs=None):\n","    logs = logs or {}\n","    logs['lr'] = K.get_value(self.model.optimizer.lr)\n","    current = logs.get(self.monitor)\n","    if current is None:\n","      logging.warning('Learning rate reduction is conditioned on metric `%s` '\n","                      'which is not available. Available metrics are: %s',\n","                      self.monitor, ','.join(list(logs.keys())))\n","    else:\n","      if self.in_cooldown():\n","        self.cooldown_counter -= 1\n","        self.wait = 0\n","\n","      if self.monitor_op(current, self.best):\n","        self.best = current\n","        self.wait = 0\n","\n","      elif not self.in_cooldown():\n","        self.wait += 1\n","        if self.wait \u003e= self.patience:\n","          \n","          if not self.freezed:\n","            for layer in self.model.layers:\n","                      layer.trainable = True\n","            self.freezed=True\n","            old_lr = K.get_value(self.model.optimizer.lr)\n","            new_lr = old_lr * 0.1\n","            K.set_value(self.model.optimizer.lr, new_lr)\n","            io_utils.print_msg(\n","                    f'\\nEpoch {epoch +1}: '\n","                    f'Unfreezing backbone layers and reducing learning rate to {new_lr}')\n","            self.cooldown_counter = self.cooldown\n","            self.wait = 0\n","\n","          else:\n","            old_lr = K.get_value(self.model.optimizer.lr)\n","            if old_lr \u003e np.float32(self.min_lr):\n","              new_lr = old_lr * self.factor\n","              new_lr = max(new_lr, self.min_lr)\n","              K.set_value(self.model.optimizer.lr, new_lr)\n","              if self.verbose \u003e 0:\n","                io_utils.print_msg(\n","                    f'\\nEpoch {epoch +1}: '\n","                    f'ReduceLROnPlateau reducing learning rate to {new_lr}.')\n","              self.cooldown_counter = self.cooldown\n","              self.wait = 0\n","\n","class CustomSaver(keras.callbacks.Callback):\n","  def __init__(self, save_path, save_name, frequency):\n","    self.save_path = save_path\n","    self.save_name = save_name\n","    self.frequency = frequency\n","\n","  def on_epoch_end(self, epoch, logs={}):\n","      if (epoch+1) % self.frequency == 0 :\n","          name = self.save_path + self.save_name + f'{epoch+1:03d}.h5'\n","          self.model.save(name)\n","          io_utils.print_msg(\n","                    f'\\nEpoch {epoch + 1}:'\n","                    f'saving model to {name}')\n","\n","model_path, model_name = './model_weight/DLv3+sgd0.01+unfreeze/', 'sgd0.01_epoch_'\n","model_path_best = './model_weight/DLv3+sgd0.01+unfreeze/sgd0.01.h5'\n","csv_name = './model_weight/DLv3+sgd0.01+unfreeze/sgd0.01.csv'\n","\n","custom_saver = CustomSaver(model_path, model_name ,frequency=10)\n","reduce_lr = unfreeze_layers_reduce_lr(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', min_delta=1e-4, cooldown=0, min_lr=0.0001,)\n","save_best = tf.keras.callbacks.ModelCheckpoint(model_path_best, monitor='val_loss', verbose=0, save_best_only=True,)\n","write_log = tf.keras.callbacks.CSVLogger(csv_name, separator=',', append=True)\n","\n","cb_list = [custom_saver, reduce_lr, save_best, write_log]"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4934,"status":"ok","timestamp":1660909383185,"user":{"displayName":"이우원","userId":"05495556713808915653"},"user_tz":-540},"id":"FpXwPVXzwJur","outputId":"9cf48d30-081b-4c0b-c106-c1dc9297809a"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"]}],"source":["# model = DeeplabV3Plus(image_size=IMAGE_SIZE, num_classes=NUM_CLASSES)\n","model = tf.keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/collage/segmentation/model_weight/DLv3+sgd0.01+unfreezesgd0.01_epoch_020.h5')\n","loss = keras.losses.BinaryCrossentropy()\n","model.compile(\n","    optimizer=keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True),\n","    loss=loss,\n","    metrics=[\"accuracy\", tf.keras.metrics.BinaryIoU(),],\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"GJoClIVd5Y9j"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","5748/5748 [==============================] - 5973s 1s/step - loss: 0.0961 - accuracy: 0.9614 - binary_io_u: 0.9230 - val_loss: 0.3183 - val_accuracy: 0.8937 - val_binary_io_u: 0.7844 - lr: 0.0100\n","Epoch 2/100\n","5748/5748 [==============================] - 3787s 659ms/step - loss: 0.0837 - accuracy: 0.9667 - binary_io_u: 0.9332 - val_loss: 0.5899 - val_accuracy: 0.8055 - val_binary_io_u: 0.6169 - lr: 0.0100\n","Epoch 3/100\n","5748/5748 [==============================] - ETA: 0s - loss: 0.0744 - accuracy: 0.9706 - binary_io_u: 0.9407\n","Epoch 3: Unfreezing backbone layers and reducing learning rate to 0.0009999999776482583\n","5748/5748 [==============================] - 3787s 659ms/step - loss: 0.0744 - accuracy: 0.9706 - binary_io_u: 0.9407 - val_loss: 2.4753 - val_accuracy: 0.6735 - val_binary_io_u: 0.3664 - lr: 0.0100\n","Epoch 4/100\n","5748/5748 [==============================] - 3791s 659ms/step - loss: 0.0672 - accuracy: 0.9735 - binary_io_u: 0.9465 - val_loss: 0.1140 - val_accuracy: 0.9612 - val_binary_io_u: 0.9189 - lr: 1.0000e-03\n","Epoch 5/100\n","5748/5748 [==============================] - 3788s 659ms/step - loss: 0.0652 - accuracy: 0.9744 - binary_io_u: 0.9482 - val_loss: 0.1148 - val_accuracy: 0.9612 - val_binary_io_u: 0.9189 - lr: 1.0000e-03\n","Epoch 6/100\n","5748/5748 [==============================] - ETA: 0s - loss: 0.0641 - accuracy: 0.9748 - binary_io_u: 0.9490\n","Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0004999999655410647.\n","5748/5748 [==============================] - 3788s 659ms/step - loss: 0.0641 - accuracy: 0.9748 - binary_io_u: 0.9490 - val_loss: 0.1159 - val_accuracy: 0.9612 - val_binary_io_u: 0.9188 - lr: 1.0000e-03\n","Epoch 7/100\n","5748/5748 [==============================] - 3788s 659ms/step - loss: 0.0633 - accuracy: 0.9752 - binary_io_u: 0.9498 - val_loss: 0.1152 - val_accuracy: 0.9616 - val_binary_io_u: 0.9195 - lr: 5.0000e-04\n","Epoch 8/100\n","5748/5748 [==============================] - ETA: 0s - loss: 0.0628 - accuracy: 0.9754 - binary_io_u: 0.9501\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00024999998277053237.\n","5748/5748 [==============================] - 3788s 659ms/step - loss: 0.0628 - accuracy: 0.9754 - binary_io_u: 0.9501 - val_loss: 0.1157 - val_accuracy: 0.9616 - val_binary_io_u: 0.9195 - lr: 5.0000e-04\n","Epoch 9/100\n","5748/5748 [==============================] - 3789s 659ms/step - loss: 0.0624 - accuracy: 0.9755 - binary_io_u: 0.9504 - val_loss: 0.1154 - val_accuracy: 0.9617 - val_binary_io_u: 0.9197 - lr: 2.5000e-04\n","Epoch 10/100\n","5748/5748 [==============================] - ETA: 0s - loss: 0.0622 - accuracy: 0.9756 - binary_io_u: 0.9506\n","Epoch 10:saving model to ./model_weight/DLv3+sgd0.01+unfreezesgd0.01_epoch_010.h5\n","\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00012499999138526618.\n","5748/5748 [==============================] - 3792s 660ms/step - loss: 0.0622 - accuracy: 0.9756 - binary_io_u: 0.9506 - val_loss: 0.1156 - val_accuracy: 0.9617 - val_binary_io_u: 0.9197 - lr: 2.5000e-04\n","Epoch 11/100\n","5748/5748 [==============================] - 3790s 659ms/step - loss: 0.0620 - accuracy: 0.9757 - binary_io_u: 0.9508 - val_loss: 0.1155 - val_accuracy: 0.9617 - val_binary_io_u: 0.9197 - lr: 1.2500e-04\n","Epoch 12/100\n","5748/5748 [==============================] - ETA: 0s - loss: 0.0619 - accuracy: 0.9757 - binary_io_u: 0.9508\n","Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0001.\n","5748/5748 [==============================] - 3790s 659ms/step - loss: 0.0619 - accuracy: 0.9757 - binary_io_u: 0.9508 - val_loss: 0.1156 - val_accuracy: 0.9617 - val_binary_io_u: 0.9197 - lr: 1.2500e-04\n","Epoch 13/100\n","5748/5748 [==============================] - 3789s 659ms/step - loss: 0.0618 - accuracy: 0.9758 - binary_io_u: 0.9509 - val_loss: 0.1156 - val_accuracy: 0.9617 - val_binary_io_u: 0.9198 - lr: 1.0000e-04\n","Epoch 14/100\n","3736/5748 [==================\u003e...........] - ETA: 21:29 - loss: 0.0626 - accuracy: 0.9755 - binary_io_u: 0.9503"]},{"ename":"NotFoundError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-14-47821d22ba8b\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit(train_dataset, validation_data=val_dataset,\n\u001b[0;32m----\u003e 2\u001b[0;31m                     callbacks=cb_list, epochs=100)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---\u003e 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFoundError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) NOT_FOUND:  /content/drive/MyDrive/Colab Notebooks/collage/segmentation/data/rawdata/humanparsing/val/Images/0003686.jpg; No such file or directory\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]]\n\t [[confusion_matrix/assert_non_negative/assert_less_equal/Assert/AssertGuard/else/_1/confusion_matrix/assert_non_negative/assert_less_equal/Assert/AssertGuard/Assert/data_2/_18]]\n  (1) NOT_FOUND:  /content/drive/MyDrive/Colab Notebooks/collage/segmentation/data/rawdata/humanparsing/val/Images/0003686.jpg; No such file or directory\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_28735]"]}],"source":["history = model.fit(train_dataset, validation_data=val_dataset,\n","                    callbacks=cb_list, epochs=100)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UfpmC1UyvkCZ"},"outputs":[],"source":["plt.plot(history.history[\"loss\"])\n","plt.title(\"Training Loss\")\n","plt.ylabel(\"loss\")\n","plt.xlabel(\"epoch\")\n","plt.plot(history.history[\"accuracy\"])\n","plt.title(\"Training Accuracy\")\n","plt.ylabel(\"accuracy\")\n","plt.xlabel(\"epoch\")\n","plt.show()\n","\n","plt.plot(history.history[\"val_loss\"])\n","plt.title(\"Validation Loss\")\n","plt.ylabel(\"val_loss\")\n","plt.xlabel(\"epoch\")\n","plt.plot(history.history[\"val_accuracy\"])\n","plt.title(\"Validation Accuracy\")\n","plt.ylabel(\"val_accuracy\")\n","plt.xlabel(\"epoch\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O7pg_Id4OpJY"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"DL_v3+unfreeze_sgd0.01","provenance":[{"file_id":"https://github.com/keras-team/keras-io/blob/master/examples/vision/ipynb/deeplabv3_plus.ipynb","timestamp":1659321316639}],"version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":0}